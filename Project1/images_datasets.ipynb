{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de646dd6",
   "metadata": {},
   "source": [
    "**YOUR NAMES HERE**\n",
    "\n",
    "Spring 2026\n",
    "\n",
    "CS 443: Bio-inspired Machine Learning\n",
    "\n",
    "# Project 1 | Hebbian Learning\n",
    "\n",
    "The primary goal of this project is to explore how the biological Hebbian learning rule can be used for machine learning tasks as a viable alternative to artificial neural networks that rely exclusively on the backpropagation algorithm. The focus will be on using bio-inspired neural networks to achieve image classification accuracies that are:\n",
    "- close to state-of-the-art for MNIST.\n",
    "- competitive with backpropagation-based networks of comparable complexity on the CIFAR-10 image dataset.\n",
    "\n",
    "Another goal of this project is to develop a TensorFlow-based, Keras-like, neural network library that will be leveraged and expanded upon in all subsequent projects throughout the semester. The library will allow neural networks to either:\n",
    "- run on your laptop's central processing unit (CPU), as in CS343.\n",
    "- be accelerated on graphics processing units (GPUs) in the cloud with minimal code changes (i.e. run substantially faster than on your laptop).\n",
    "\n",
    "#### Week 1: TensorFlow, Datasets, and Custom Neural Network Library\n",
    "\n",
    "The areas of focus this week are on:\n",
    "- refreshing your memory of TensorFlow.\n",
    "- gaining familiarity with running neural networks on GPUs and local vs. cloud computing workflows.\n",
    "- building a pipeline to load and preprocess the MNIST and CIFAR-10 image datasets.\n",
    "- build an simple single-layer artificial neural network using the TensorFlow low-level API and train it to classify images on MNIST and CIFAR-10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a962e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "plt.style.use(['seaborn-v0_8-colorblind', 'seaborn-v0_8-darkgrid'])\n",
    "plt.show()\n",
    "plt.rcParams.update({'font.size': 18})\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628dae18",
   "metadata": {},
   "source": [
    "## Task 1: Build an image dataset preprocessing pipeline\n",
    "\n",
    "We will work with the MNIST or CIFAR-10 image datasets for a large portion of the semester so it will be helpful to develop a standardized and customizable pipeline for loading, preprocessing, and dividing up the datasets into train/val/test sets. Once built, the pipeline will enable loading either datasets with only several lines of code. Because we want our code to be able to run on GPUs, **you should write your pipeline in TensorFlow's low-level API rather than NumPy**.\n",
    "\n",
    "**Note:** As you are refreshing your memory of TensorFlow, having the [TensorFlow documentation](https://www.tensorflow.org/api_docs/python/tf) and the CS343 TensorFlow tutorial (`TensorFlowTutorial.ipynb`) open is a good idea:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a102f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from image_datasets import get_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f942a18c",
   "metadata": {},
   "source": [
    "### 1a. Loading and preprocessing CIFAR-10\n",
    "\n",
    "In the `get_dataset` function of `image_datasets.py` use TensorFlow to load in and preprocess the CIFAR-10 dataset according to the specifications in the docstring. \n",
    "\n",
    "CIFAR-10 is similar to STL-10 in that it consists of small color images of natural scenes, but it is considerably larger ($N=60,000$ vs $N=5,000$). Here is some more information about CIFAR-10:\n",
    "- Each RGB image is 32x32 resolution\n",
    "- Each image is one of 10 classes: `airplane`, `automobile` `bird` `cat` `deer` `dog` `frog` `horse` `ship` and `truck`\n",
    "- Unlike STL-10 whose images come from the famous ImageNet dataset, CIFAR-10 images are a subset of the (*also famous*) [80 Million Tiny Images](https://en.wikipedia.org/wiki/80_Million_Tiny_Images) dataset, which was released in 2009.\n",
    "\n",
    "\n",
    "**Notes and reminders:**\n",
    "1. For convenience, use TensorFlow Keras to download CIFAR-10 directly from the internet.\n",
    "2. TensorFlow provides the CIFAR-10 images in 8-bit format, meaning the pixel values are integer values between 0 (dark) and 255 (light). Before you perform any preprocessing to the images (e.g. centering, standardizing), scale the features to floats between `0.0` and `1.0`.\n",
    "3. The goal is to practice using TensorFlow so you should **not** be using NumPy (i.e. do **not** import it!).\n",
    "4. See below for a refresher on the **'global'** standardization method.\n",
    "\n",
    "#### Global RGB standardization\n",
    "\n",
    "This approach to standardizing data refers:\n",
    "\n",
    "$$\n",
    "X_{\\text{norm}} = \\frac{ X - (R_{\\text{mean}}, G_{\\text{mean}}, B_{\\text{mean}})}{(R_{\\text{stddev}}, G_{\\text{stddev}}, B_{\\text{stddev}})}\n",
    "$$\n",
    "\n",
    "where $X$ is the original CIFAR-10 dataset (*either train or test set*) with shape (`(N, Iy, Ix, 3)`), $(R_{\\text{mean}}, G_{\\text{mean}}, B_{\\text{mean}})$ has shape `(3,)` and is the global mean of all images within each RGB color channel, and $(R_{\\text{stddev}}, G_{\\text{stddev}}, B_{\\text{stddev}})$ also has shape `(3,)` and is the global standard deviation of all images within each RGB color channel."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3748e86f",
   "metadata": {},
   "source": [
    "#### Test: CIFAR-10 loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed7fc74",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, y_test = get_dataset('cifar10', norm_method='none')\n",
    "\n",
    "print('The shape of your CIFAR-10 train and test sets are:')\n",
    "print(f'{x_train.shape=} {y_train.shape=}')\n",
    "print(f'{x_test.shape=} {y_test.shape=}')\n",
    "print('and should be:')\n",
    "print('''x_train.shape=TensorShape([50000, 3072]) y_train.shape=TensorShape([50000])\n",
    "x_test.shape=TensorShape([10000, 3072]) y_test.shape=TensorShape([10000])''')\n",
    "print()\n",
    "print(f'Your training set min/max are {tf.reduce_min(x_train)}/{tf.reduce_max(x_train)} and should be 0.0/1.0')\n",
    "print(f'The unique set of your train labels are {np.unique(y_train)} and should be [0 1 2 3 4 5 6 7 8 9]')\n",
    "print(f'The unique set of your test labels are {np.unique(y_test)} and should be [0 1 2 3 4 5 6 7 8 9]')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf9a6e1",
   "metadata": {},
   "source": [
    "#### Test preserving original spatial dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91f4d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, y_test = get_dataset('cifar10', norm_method='none', flatten=False)\n",
    "\n",
    "print('The shape of your CIFAR-10 train and test sets are:')\n",
    "print(f'{x_train.shape=} {y_train.shape=}')\n",
    "print(f'{x_test.shape=} {y_test.shape=}')\n",
    "print('and should be:')\n",
    "print('''x_train.shape=TensorShape([50000, 32, 32, 3]) y_train.shape=TensorShape([50000])\n",
    "x_test.shape=TensorShape([10000, 32, 32, 3]) y_test.shape=TensorShape([10000])''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cacad6d",
   "metadata": {},
   "source": [
    "#### Test standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e59057",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, y_test = get_dataset('cifar10', norm_method='global')\n",
    "\n",
    "print('The shape of your CIFAR-10 train and test sets are:')\n",
    "print(f'{x_train.shape=} {y_train.shape=}')\n",
    "print(f'{x_test.shape=} {y_test.shape=}')\n",
    "print('and should be:')\n",
    "print('''x_train.shape=TensorShape([50000, 3072]) y_train.shape=TensorShape([50000])\n",
    "x_test.shape=TensorShape([10000, 3072]) y_test.shape=TensorShape([10000])''')\n",
    "print()\n",
    "print(f'The min/max of your training set is {tf.reduce_min(x_train):.4f}/{tf.reduce_max(x_train):.4f}')\n",
    "print('and they should be                  -1.9892/2.1268')\n",
    "print(f'The min/max of your test set is {tf.reduce_min(x_test):.4f}/{tf.reduce_max(x_test):.4f}')\n",
    "print('and they should be              -1.9892/2.1268')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8009f4",
   "metadata": {},
   "source": [
    "#### Test centering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f32eb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, y_test = get_dataset('cifar10', norm_method='center')\n",
    "\n",
    "print('The shape of your CIFAR-10 train and test sets are:')\n",
    "print(f'{x_train.shape=} {y_train.shape=}')\n",
    "print(f'{x_test.shape=} {y_test.shape=}')\n",
    "print('and should be:')\n",
    "print('''x_train.shape=TensorShape([50000, 3072]) y_train.shape=TensorShape([50000])\n",
    "x_test.shape=TensorShape([10000, 3072]) y_test.shape=TensorShape([10000])''')\n",
    "print()\n",
    "print(f'The min/max of your training set is {tf.reduce_min(x_train):.4f}/{tf.reduce_max(x_train):.4f}')\n",
    "print('and they should be                  -0.4914/0.5535')\n",
    "print(f'The min/max of your test set is {tf.reduce_min(x_test):.4f}/{tf.reduce_max(x_test):.4f}')\n",
    "print('and they should be              -0.4914/0.5535')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb50952",
   "metadata": {},
   "source": [
    "### 1b. Creating train and validation splits\n",
    "\n",
    "Given that CIFAR-10 is provided without a validation set, write code in the `train_val_split` fuction in `image_datasets.py`  to create one by paring down the training set. Afterwards, test out your code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb06fc2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from image_datasets import train_val_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7788f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_split, y_train_split, x_val_split, y_val_split = train_val_split(x_train, y_train, prop_val=0.25)\n",
    "\n",
    "print('The shape of your CIFAR-10 train and val sets are:')\n",
    "print(f'{x_train_split.shape=} {y_train_split.shape=}')\n",
    "print(f'{x_val_split.shape=} {y_val_split.shape=}')\n",
    "print('and should be:')\n",
    "print('''x_train_split.shape=TensorShape([37500, 3072]) y_train_split.shape=TensorShape([37500])\n",
    "x_val_split.shape=TensorShape([12500, 3072]) y_val_split.shape=TensorShape([12500])''')\n",
    "print()\n",
    "print(f'The first few val class labels are\\n{y_val_split[:6]} and they should be\\n[3 5 2 2 0 1]')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "647dfe64",
   "metadata": {},
   "source": [
    "### 1c. Visualize CIFAR-10 samples\n",
    "\n",
    "Create a 7x7 grid showing first 49 CIFAR-10 training images in a grid/montage. You should use the class string of each sample as the title and there should not be any clutter created by grid lines/axes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823eeabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "classnames = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32d1b74",
   "metadata": {},
   "source": [
    "### 1d. Add support for MNIST\n",
    "\n",
    "Modify `get_dataset` to load and preprocess the MNIST dataset.\n",
    "\n",
    "**Notes:**\n",
    "1. TensorFlow Keras should be used to download the dataset from the internet (*similar to CIFAR-10*).\n",
    "2. Since MNIST consists of grayscale 28x28 images, the dataset comes without a color channel dimension (i.e. the shape is `(N, 28, 28)` rather than `(N, 28, 28, 1)`). It may be helpful to add a singleton dimension so that your preprocessing code works regardless of whether CIFAR-10 or MNIST is selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8657c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, y_test = get_dataset('mnist')\n",
    "\n",
    "print('--------------')\n",
    "print('Your preprocessed shapes are:')\n",
    "print(f'{x_train.shape=} {x_test.shape=}\\n{y_train.shape=} {y_test.shape=}')\n",
    "print('and should be:')\n",
    "print('''x_train.shape=TensorShape([60000, 784]) x_test.shape=TensorShape([10000, 784])\n",
    "y_train.shape=TensorShape([60000]) y_test.shape=TensorShape([10000])\n",
    "''')\n",
    "print('--------------')\n",
    "print(f'Train min/max: {tf.reduce_min(x_train):.3f}/{tf.reduce_max(x_train):.3f} and should be -0.424/2.822')\n",
    "print(f'Test min/max: {tf.reduce_min(x_test):.3f}/{tf.reduce_max(x_test):.3f} and should be -0.424/2.822')\n",
    "print(f'Training samples {x_train.dtype=}, Test samples {x_test.dtype=}')\n",
    "print(f'Training labels {y_train.dtype=}, Test labels {y_test.dtype=}')\n",
    "print(f'Labels present in training set: {tf.sort(tf.unique(y_train)[0])}')\n",
    "print(f'Labels present  in test set: {tf.sort(tf.unique(y_test)[0])}')\n",
    "print('[You should have tf.float32 for x and tf.int32 for y]')\n",
    "print('--------------')\n",
    "print(f'First 5 training labels: {y_train[:5]} and should be [5 0 4 1 9]')\n",
    "print(f'First 5 test labels: {y_test[:5]} and should be [7 2 1 0 4]')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487e6599",
   "metadata": {},
   "source": [
    "### 1e. Visualize MNIST samples\n",
    "\n",
    "Load in a fresh copy of MNIST, make a validation set using the default split, then use `draw_grid_image()` in `viz.py` in the cell below to create a `10x10` grid of the first 100 MNIST validation sample images.\n",
    "\n",
    "This function places the image samples on a *single canvas* image (i.e. does not create subplots). Plotting one image instead an 2D array is more efficient (*you will be using this to visualize weights many times during training)*!\n",
    "\n",
    "If you selected the first `N_val` samples for your validation set, the first two rows of your image should consist of the following digits:\n",
    "\n",
    "```\n",
    "[[5 3 5 0 0 1 8 4 3 4]\n",
    " [0 7 0 3 3 5 3 4 6 1]]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8398095f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from viz import draw_grid_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e18657",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs444",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
