{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**YOUR NAMES HERE**\n",
    "\n",
    "Spring 2026\n",
    "\n",
    "CS 443: Bio-Inspired Machine Learning\n",
    "\n",
    "Project 1: Hebbian Learning\n",
    "\n",
    "#### Week 1: TensorFlow, Datasets, and Custom Neural Network Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use(['seaborn-v0_8-colorblind', 'seaborn-v0_8-darkgrid'])\n",
    "plt.rcParams.update({'font.size': 18})\n",
    "\n",
    "np.set_printoptions(suppress=True, precision=4)\n",
    "\n",
    "# Automatically reload your external source code\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4. Train `LinearDecoder` on MNIST and CIFAR-10\n",
    "\n",
    "Woohoo! Your linear decoder is built and tested! Time for some fun! ðŸ˜Ž"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train in a reasonable amount of time, upload your project code to CoCalc so that you can train on the GPU (*See detailed instructions and demos in lecture*).\n",
    "\n",
    "*As noted on the website, if you have a higher-end Macbook with a Pro or Max chip and â‰¥ 16 GB of memory, you could probably run this workload on your computer if you would prefer. This is entirely optional and the cloud will almost certainly be faster than even the fastest Mac. Setting this up would just provide some extra convenience/flexibility. See the [macOS instructions](https://cs.colby.edu/courses/S26/cs443/software.html#tf) for setup.*\n",
    "\n",
    "Run the cell below to make sure TensorFlow is running on the GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if len(gpus) > 0:\n",
    "    print('Running on the GPU')\n",
    "else:\n",
    "    print('NOT running on the GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from image_datasets import get_dataset, train_val_split\n",
    "from decoder_nets import LinearDecoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4a. Train `LinearDecoder` on MNIST on the GPU\n",
    "\n",
    "This will be a \"hello world\" test to make sure your `fit` method is working.\n",
    "\n",
    "Write code in the cell below to load in MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, y_test = get_dataset('mnist', verbose=False)\n",
    "x_train_split, y_train_split, x_val_split, y_val_split = train_val_split(x_train, y_train)\n",
    "\n",
    "# KEEP ME\n",
    "print(f'Your training set data have shape {x_train_split.shape} and they should be (54000, 784)')\n",
    "print(f'Your training set labels have shape {y_train_split.shape} and they should be (54000,)')\n",
    "print(f'Your val set data have shape {x_val_split.shape} and they should be (6000, 784)')\n",
    "print(f'Your val set labels have shape {y_val_split.shape} and they should be (6000,)')\n",
    "print(f'Your test set data have shape {x_test.shape} and they should be (10000, 784)')\n",
    "print(f'Your test set labels have shape {y_test.shape} and they should be (10000,)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train `LinearDecoder` in the cell below on MNIST for `10` epochs and a batch size of `256`! Print out your accuracy on the test set when training is done.\n",
    "\n",
    "The **entire** process of training and evaluating test accuracy should take no more than 30 seconds (*at most!*). If it is taking longer, seek help.\n",
    "\n",
    "Your print outs should look something like:\n",
    "\n",
    "```\n",
    "---------------------------------------------------------------------------\n",
    "Dense layer output(Output Layer) shape: [1, 10]\n",
    "---------------------------------------------------------------------------\n",
    "Epoch 0/9, Training loss 0.533, Val loss 0.284, Val acc SURPRISE\n",
    "Epoch 0 took: 2.0 secs\n",
    "Epoch 1/9, Training loss 0.322, Val loss 0.257, Val acc SURPRISE\n",
    "Epoch 1 took: 1.1 secs\n",
    "Epoch 2/9, Training loss 0.299, Val loss 0.243, Val acc SURPRISE\n",
    "Epoch 2 took: 1.1 secs\n",
    "...\n",
    "Epoch 9/9, Training loss 0.272, Val loss 0.234, Val acc SURPRISE\n",
    "Epoch 9 took: 1.1 secs\n",
    "Finished training after 10 epochs!\n",
    "Linear Decoder MNIST Test accuracy: SURPRISE%\n",
    "Training took: 12.55 secs\n",
    "```\n",
    "\n",
    "The val and test accuracy should be satisfyingly high â€” in the 90s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KEEP THIS SEED\n",
    "tf.random.set_seed(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4b. Train `LinearDecoder` on MNIST on the CPU\n",
    "\n",
    "To appreciate the advantage for training deep networks on GPUs instead of your computer's CPU, copy-paste your code above that trains your `LinearDecoder` net on MNIST below. Instead of running it on CoCalc, run it locally on your computer. Be sure to print out the time per epoch.\n",
    "\n",
    "*If the net takes >2 minutes per epoch on your computer, just train for one epoch then call it quits :)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KEEP THIS SEED\n",
    "tf.random.set_seed(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4c. Questions\n",
    "\n",
    "**Question 1:** Approximately how long did it take for 1 epoch of training with and without the GPU. Compute the relative compute time (`gpu_time_per_epoch`/`cpu_time_per_epoch`). What do you think?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer 1:** YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4d. Train `LinearDecoder` on CIFAR-10\n",
    "\n",
    "Now let's train on CIFAR-10. Run this (*and all subsequent large training sessions*) on CoCalc/the GPU ðŸ˜Š\n",
    "\n",
    "Write code in the cell below to load in CIFAR-10 with global RGB normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, y_test = get_dataset('cifar10', verbose=False)\n",
    "x_train_split, y_train_split, x_val_split, y_val_split = train_val_split(x_train, y_train)\n",
    "\n",
    "# KEEP ME\n",
    "print(f'Your training set data have shape {x_train_split.shape} and they should be (45000, 3072)')\n",
    "print(f'Your training set labels have shape {y_train_split.shape} and they should be (45000,)')\n",
    "print(f'Your val set data have shape {x_val_split.shape} and they should be (5000, 3072)')\n",
    "print(f'Your val set labels have shape {y_val_split.shape} and they should be (5000,)')\n",
    "print(f'Your test set data have shape {x_test.shape} and they should be (10000, 3072)')\n",
    "print(f'Your test set labels have shape {y_test.shape} and they should be (10000,)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train `LinearDecoder` on CIFAR-10 in the cell below for `10` epochs and use a batch size of `256`.\n",
    "\n",
    "*You should anticipate no more than ~1 min of total training time on the GPU. If this is far off, please seek help.*\n",
    "\n",
    "Plot the training and val loss over epochs. Put test acc in the title. *If everything is working, your training and validation loss should steadily decrease then start to plateau by the end of training.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KEEP THIS SEED\n",
    "tf.random.set_seed(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4e. Experiment: Effect of batch size on runtime and accuracy\n",
    "\n",
    "To develop your intuition about how the choice of batch size generally affects runtime and accuracy on a dataset like CIFAR-10, run an experiment in which fresh `LinearDecoder` nets are trained for `10` epochs with one of the following batch sizes:<br/>\n",
    "`[128, 256, 512, 1024, 2048]`. After each training run, record the test accuracy and runtime.\n",
    "\n",
    "Create two plots:\n",
    "1. The test accuracy (y axis) as a function of the batch size (x axis). There should be 5 markers joined by a single curve.\n",
    "2. The runtime (y axis) as a function of the batch size (x axis). There should be 5 markers joined by a single curve.\n",
    "\n",
    "**Note:**\n",
    "- Your `fit` method prints the runtime per epoch, but in this task you should record the total runtime over training and prediction. (in seconds). To do this, it may make sense to use the time module to record the total time in the notebook cell below.\n",
    "- You should be running this on the GPU!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KEEP THIS SEED\n",
    "tf.random.set_seed(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4f. Questions\n",
    "\n",
    "**Question 2:** What do the plots suggest to you about the relationship between batch size and accuracy? Please be specific,citing evidence from your plots.\n",
    "\n",
    "**Question 3:** Do you find this relationship surprising? Why or why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer 2:** YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer 3:** YOUR ANSWER HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs444",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
