{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6083f220",
   "metadata": {},
   "source": [
    "**Jacob Petty, Sardor Nodirov, and Saad Khan**\n",
    "\n",
    "Spring 2026\n",
    "\n",
    "CS 443: Bio-inspired Machine Learning\n",
    "\n",
    "Project 1: Hebbian Learning\n",
    "\n",
    "#### Week 4: Decoding class labels from Competitive Hebbian Network activations\n",
    "\n",
    "You will use single layer artificial neural networks to **decode** (i.e. predict) the class label corresponding to each MNIST and CIFAR-10 sample **encoded** (i.e. processed) by your Competitive Hebbian Network. This will take advantage of the Competitive Hebbian Network weights that you saved off last week. Once you obtain the Competitive Hebbian Network activations, you will predict the class labels and compute the classification accuracy for each dataset obtained by this **encoder-decoder** neural network architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81130992",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "plt.style.use(['seaborn-v0_8-colorblind', 'seaborn-v0_8-darkgrid'])\n",
    "plt.show()\n",
    "plt.rcParams.update({'font.size': 18})\n",
    "\n",
    "np.set_printoptions(suppress=True, precision=3)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fabf835",
   "metadata": {},
   "source": [
    "## Task 9: Decode class labels from Hebbian network activations\n",
    "\n",
    "The goal of this task is to train your linear and nonlinear decoder networks to classify MNIST digits (then later on CIFAR-10 classes) based on the Hebbian activations to each sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90fee253",
   "metadata": {},
   "outputs": [],
   "source": [
    "from image_datasets import get_dataset, train_val_split\n",
    "from decoder_nets import LinearDecoder, NonlinearDecoder\n",
    "from hebb_net import HebbNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b6a636",
   "metadata": {},
   "source": [
    "### 9a. Preparing decoder inputs\n",
    "\n",
    "In the cell below:\n",
    "1. Load MNIST in train/test/validation samples. Use the default validation split.\n",
    "2. Process them with your Competitive Hebbian Network (i.e. compute their corresponding netIn values) to get the input for your decoders.\n",
    "\n",
    "**Tips:**\n",
    "- Your Hebbian network constructor has a keyword argument that you can use to load wts from a previously trained network. You should **NOT** retrain your Hebbian network here!\n",
    "- When creating your Hebbian network object, remember to build it with the same hyperparameters as you did last week (e.g. number of neurons, `k` value)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe9201d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "de17596a",
   "metadata": {},
   "source": [
    "### 9b. Train linear decoder (MNIST)\n",
    "\n",
    "Train your softmax classifier on the Hebbian network `net_in` activations obtained from processing the MNIST training set. Keep default hyperparameters except:\n",
    "1. Play around with the mini-batch size. Try starting with `256` and adjust as needed.\n",
    "2. Feel free to change the `patience` depending on your patience. A patience around `3-7` should produce good results.\n",
    "3. Try a learning rate decay patience of `3-5` with max decays set to `3-4`. Adjust as needed.\n",
    "\n",
    "#### Guidelines\n",
    "\n",
    "- **DO NOT COPY AND PASTE HYPERPARAMETERS FROM THE IRIS TEST CODE CELLS!** They will not work well for MNIST ðŸ™„\n",
    "- Training should be fairly quick (no more than a few minutes).\n",
    "- **Remember:** you are **NOT** training the linear classifier **on MNIST** â€” you are training it on the `net_in` values produced by the Competitive Hebbian Network that you trained above!\n",
    "\n",
    "Your results should be comparable to that of the linear decoder trained on the MNIST samples directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c41ec9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "af2cd8e0",
   "metadata": {},
   "source": [
    "### 9c. Analyze Linear Decoder performance\n",
    "\n",
    "Create a well-labeled plot showing the training and validation loss over epochs. Place the test accuracy of the linear classifier in your plot title.\n",
    "\n",
    "**Note:** Because the initial training and validation losses are so large compared to the final values, plotting all the values may obscure details about the eventual loss curve. I would suggest trimming out the training and validation loss values for the first few epochs to highlight the long-term trend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279db83b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e6969aeb",
   "metadata": {},
   "source": [
    "### 9d. Train nonlinear decoder (MNIST)\n",
    "\n",
    "Repeat what you did for the linear classifier with the nonlinear classifier.\n",
    "\n",
    "**Note there is one additional step:** Once you get the Hebbian network `net_in` values for the train/validation/test sets, the nonlinear decoding network proposed by Krotov & Hopfield (2019) assumes that the Hebbian network `net_in` values ($h_{ij}$) that serve as the input to the decoder are transformed by the following activation function:\n",
    "\n",
    "$$x_{ij} = max(h_{ij}, 0)^n$$\n",
    "\n",
    "where $h_{ij}$ are the Hebbian network `net_in` values. In other words, apply ReLU to the `net_in` values then raise the result to the power `n`. By default, we assume that the hyperparameter $n=4.0$.\n",
    "\n",
    "You may implement this preprocessing step in the `preprocess_nonlinear` function in `image_datasets.py`. **This additional ReLU step needs to be performed on the `net_in` values representing each of the decoder train, validation, AND test sets!!**\n",
    "\n",
    "**For full credit** your goal is to have your encoder-decoder system achieve either validation or test accuracy â‰¥ 97.5%. If this goal is not met, there will be point reductions, depending on how far below your system is from this target.\n",
    "\n",
    "Here are suggested non-default hyperparameter values:\n",
    "- patience: 5-9\n",
    "- learning rate patience: below the regular patience, 3-5\n",
    "- maximum learning rate decays: 3-4\n",
    "- loss exponent: the default should do well, though you may be able to do a bit better with an exponent of `5.0`.\n",
    "\n",
    "**Notes, reminders, and guidelines:**\n",
    "- Remember that the nonlinear decoder uses the $L^p$ loss! \n",
    "- Training should take longer than your linear decoder, but not a lot longer (rough estimate 10-20 minutes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68dda4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from image_datasets import preprocess_nonlinear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5e9f16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "67733b1a",
   "metadata": {},
   "source": [
    "### 9e: Analyze Nonlinear Decoder performance (MNIST)\n",
    "\n",
    "Create a well-labeled plot showing the training and validation loss over training epochs. Place the accuracy of the nonlinear classifier on the test set in your plot title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ead1e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cf0f2773",
   "metadata": {},
   "source": [
    "### 9f. Train linear decoder (CIFAR-10)\n",
    "\n",
    "Train the linear decoder on the `net_in` Hebbian network values obtained to the CIFAR-10 dataset to decode the class labels. Repeat your data loading and training protocols.\n",
    "\n",
    "**Notes:**\n",
    "- If you configured your Hebbian network as suggested for CIFAR-10, with 2nd place neurons being inhibited (`k=2`), set `k=2` below when creating and loading your Hebbian network below.\n",
    "- The same hyperparameters you used to decode MNIST should work fine here too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cce6768",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3ffd26e1",
   "metadata": {},
   "source": [
    "Make a well-labeled plot showing the training and validation loss over the course of training. Place the test set accuracy in the plot title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f256ccd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "753ac085",
   "metadata": {},
   "source": [
    "### 9g. Train nonlinear decoder (CIFAR-10)\n",
    "\n",
    "Train the nonlinear decoder on the `net_in` Hebbian network values obtained to the CIFAR-10 dataset to decode the class labels. Repeat your data loading and training protocols.\n",
    "\n",
    "If you configured your Hebbian network as suggested for CIFAR-10, with 2nd place neurons being inhibited (`k=2`), set `k=2` below when creating and loading your Hebbian network below.\n",
    "\n",
    "**Suggested non-default hyperparameters:**\n",
    "- Power `n` to raise Hebbian activations when applying ReLU: `2.0`\n",
    "- Loss exponent: `4.0`\n",
    "- patience: 5-9\n",
    "- learning rate patience: below the regular patience, 3-5\n",
    "- maximum learning rate decays: 3-4\n",
    "\n",
    "**For full credit** your goal is to have your encoder-decoder system achieve either validation or test accuracy â‰¥ 47%. If this goal is not met, there will be point reductions, depending on how far below your system is from this target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49811601",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6d8e9cc1",
   "metadata": {},
   "source": [
    "Make a well-labeled plot showing the training and validation loss over the course of training. Place the test set accuracy in the plot title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7d2431",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ce3dbec3",
   "metadata": {},
   "source": [
    "### 9h. Questions\n",
    "\n",
    "**Question 14:** Describe one specific case (*linear or nonlinear decoder paired with MNIST or CIFAR-10*)where the learning rate decay made a substantial difference in the validation accuracy that your encoder-decoder system achieved. What results would you have achieved with and without this technique? *You should be able to answer this question based on your training print outs; you do NOT need to retrain your networks to answer this question.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72726a9",
   "metadata": {},
   "source": [
    "**Answer 14:** YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401d51b1",
   "metadata": {},
   "source": [
    "## Extensions\n",
    "\n",
    "### General guidelines\n",
    "\n",
    "1. Never integrate extensions into your base project so that they change the expected behavior of core functions. If your extension changes the core design/behavior, no problem, duplicate your working base project and add features from there.\n",
    "2. Check the rubric to keep in mind how extensions on this project will be graded.\n",
    "3. While I may consult your code and \"written log\" of what you did, **I am grading your extensions based on what you present in your 3-5 min video.**\n",
    "3. I suggest documenting your explorations in a \"log\" or \"lab notebook\" style (i.e. documenting your thought/progression/discovery/learning process). I'm not grading your writing, so you can keep it succinct. **Whatever is most useful to you to remember what you did.** \n",
    "4. I suggest taking a hypothesis driven approach. For example \"I was curious about X so I explored Y. I found Z, which was not what I expected because..., so then tried A...\"\n",
    "5. Make plots to help showcase your results.\n",
    "6. **More is not necessarily better.** Generally, a small number of \"in-depth\" extensions count for more than many \"shallow\" extensions.\n",
    "\n",
    "### AI guidelines\n",
    "\n",
    "You may use AI in mostly any capacity for extensions. However, keep in mind:\n",
    "1. There is no need to use AI at all!\n",
    "2. You are welcome to use AI as a tool (e.g. automate something that is tedious, help you get unstuck, etc.). However, you should be coding, you should be thinking, you should be writing, you should be creating. If you are spending most (or even close to most) of your time typing into a chatbot and copy-pasting, you have probably gone too far with AI use.\n",
    "3. I don't find large volumes of AI generated code/text/plots to be particularly impressive and you risk losing my interest while grading. Remember: I'm grading your extensions based on your video presentation. **More is not necessarily better.**\n",
    "\n",
    "### Video guidelines\n",
    "\n",
    "1. Please try to keep your video to 5 minutes (*I have other projects to grade!*). If you turn in a longer video, I make no promise that I will watch more than 5 minutes.\n",
    "2. Your screen should be shared as you show me what you did. A live video of your face should also appear somewhere on the screen (e.g. picture-in-picture overlay / split screen).\n",
    "3. Your partner should join you for the video and take turns talking, but, if necessary, it is fine to have one team member present during the record the video.\n",
    "4. Do not simply read text from your notebook, do not read from a prepared script. I am not grading how polished your video presentation is (see extension grading criteria on rubric). \n",
    "5. I am looking for original and creative explorations sparked by your curiosity/interest/passion in a topic. This should be apparent in your video.\n",
    "6. Be natural,, don't feel the need to impress me with fancy language. If it is helpful, imagine that we are talking one-on-one about your extension. Tell me what you did :)\n",
    "\n",
    "### Extension ideas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0665b5",
   "metadata": {},
   "source": [
    "#### 1. Compare encoder-decoder model to end-to-end training\n",
    "\n",
    "Compare your results from this project to other end-to-end artificial neural networks trained directly on MNIST or CIFAR-10 (e.g. MLPs, CNNs). I would suggest keeping hyperparameters constant for a fair comparison. There is a lot to explore here! Here are a few questions to examine:\n",
    "- Are there differences in how rapidly the systems learn their inputs (e.g. number of training epochs needed to achieve \"good\" accuracy on the validation set)?\n",
    "- What test accuracy is achievable?\n",
    "- How does the total training time compare?\n",
    "\n",
    "In your analysis, account for the complexity/number of parameters in each system."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06b618b",
   "metadata": {},
   "source": [
    "#### 2. Hyperparameter explorations\n",
    "\n",
    "Explore how the hyperparameters affect classification accuracy. Can you improve upon the results from the base project?\n",
    "\n",
    "- Remember, the encoder has numerous hyperparameters to experiment with. For example, remember that you can also control the dimension of the \"embedding\" performed by the Hebbian network (i.e. number of neurons in the net), the amount of inhibition, etc. \n",
    "- Use a grid or random search for encoder and/decoder networks to optimize performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189c8757",
   "metadata": {},
   "source": [
    "#### 3. Use your CS 343 Softmax network as the linear decoder\n",
    "\n",
    "This will require a few updates to support the Adam optimizer (that you implemented in the CS 343 CNN project) and validation sets.\n",
    "\n",
    "Copy `softmax_layer.py` from your CS343 MLP project to your working directory. Also copy `optimizer.py` from your CS343 CNN project.\n",
    "\n",
    "Make the following changes to `fit()` in `softmax_layer.py`:\n",
    "1. Switch your optimizer from SGD to Adam. This will involve creating two `Adam` objects: one for the weights, one for the bias. Also, be sure to set the Adam learning rate based on the value passed into `fit()`.\n",
    "2. Add support in `fit()` for a validation set by adding the keyword arguments: `x_val=None, y_val=None`. If `verbose > 0` print out the accuracy and loss over the entire validation set. \n",
    "3. If `verbose > 0` convert your print outs to happen in terms of epochs rather than iterations (e.g. every epoch, not every 100 iterations). Add a keyword argument `val_freq=50` to specify how often (in epochs) to check and print out the validation accuracy and loss. Be sure to always print out the validation accuracy and loss on the first and last epoch regardless of the `val_freq` value.\n",
    "4. Have `fit()` return both the train and validation loss as Python lists or ndarrays. In cases when you do not pass in a validation set, the returned validation loss list may be `None` and that's ok.\n",
    "\n",
    "The network should train similarily to your Tensorflow version. Compare/analyze runtime performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d18af83",
   "metadata": {},
   "source": [
    "#### 4. Encode an image dataset of your choice with the Hebbian network\n",
    "\n",
    "For example, Fashion MNIST, STL-10 or CIFAR-100. If your images contain color, I suggest either converting to grayscale or flattening the color channels when constructing your feature vectors (e.g. `(32, 32, 3)` color image made into a `(3072,)` vector).\n",
    "\n",
    "Some areas to explore:\n",
    "- Visualize the weights. Analyze how hyperparameters affect the structure.\n",
    "- Compare decoding accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f131579c",
   "metadata": {},
   "source": [
    "#### 5. Learning rate decay alternatives\n",
    "\n",
    "Krotov & Hopfield (2019) not only used step decays, similar to the approach taken in the project, but in some cases also linear decays, where the linear rate decayed by a fixed amount on every epoch. There are many other ways to the decay learning rate. Implement the linear decay or your own variant (for either encoder and/or decoder network) and explore whether it improves decoding performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2c57e5",
   "metadata": {},
   "source": [
    "#### 6. Early stopping alternatives\n",
    "\n",
    "There are many other ways to implement early stopping. For example, you could abort training when the current val loss exceeds the recent moving average. Implement this or your own variant (for either encoder and/or decoder network) and explore whether it improves decoding performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4ead03",
   "metadata": {},
   "source": [
    "#### 7. Confusion matrix and error analysis of MNIST classification\n",
    "\n",
    "For one or both classifier, make a confusion matrix of the digit classifications. Use your confusion matrix to gain insight into misclassifications. Run follow-up analyses/training sessions to explore patterns in more depth. For example, if two classes are frequently misclassified, how neurons in the Hebbian network develop receptive fields that resemble each? Are the weights resembling the two classes strongly correlated (and how?)? To what degree are inhibitory weights learned for these neurons? What happens if you train the Hebbian network on only samples belonging to the two classes â€” do classes of either class become less/more confusable? And so forth..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492e880a",
   "metadata": {},
   "source": [
    "<!-- ### 8. Implement the Generalized Hebbian Algorithm (GHA) and compare to PCA\n",
    "\n",
    "The GHA provides an incremental version of PCA â€” compute PCA one sample at a time over a number of training epochs. This approach can be helpful when you want to run PCA on a large dataset, but the dataset is too large to fit in your computer's memory (e.g. perhaps STL-10 at full 96x96 resolution). \n",
    "\n",
    "Implement GHA then show for a large dataset (e.g. STL-10) that GHA computes the PCA representation, whereas regular PCA (e.g. from CS251/2) fails. Plot what the image samples look like over training epochs when projected to PCA space and then back to the original data space (i.e. filtered by the learned principle components / network weights). If this sounds interesting, please see me for guidance. -->\n",
    "\n",
    "#### 8. Experiment with different decoder architectures\n",
    "\n",
    "Create one or more different nonlinear decoders in TensorFlow (e.g. MLP, CNN). Compare performance/accuracy with the nonlinear one in the project."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs444",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
