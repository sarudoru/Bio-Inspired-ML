{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c500ae22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use(['seaborn-v0_8-colorblind', 'seaborn-v0_8-darkgrid'])\n",
    "plt.rcParams.update({'font.size': 18})\n",
    "\n",
    "np.set_printoptions(suppress=True, precision=4)\n",
    "\n",
    "# Automatically reload your external source code\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08649d10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT running on the GPU\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if len(gpus) > 0:\n",
    "    print('Running on the GPU')\n",
    "else:\n",
    "    print('NOT running on the GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d1de04",
   "metadata": {},
   "source": [
    "On CPU for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12a90e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from image_datasets import get_dataset, train_val_split\n",
    "from decoder_nets import LinearDecoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a38a88ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your training set data have shape (54000, 784) and they should be (54000, 784)\n",
      "Your training set labels have shape (54000,) and they should be (54000,)\n",
      "Your val set data have shape (6000, 784) and they should be (6000, 784)\n",
      "Your val set labels have shape (6000,) and they should be (6000,)\n",
      "Your test set data have shape (10000, 784) and they should be (10000, 784)\n",
      "Your test set labels have shape (10000,) and they should be (10000,)\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train, x_test, y_test = get_dataset('mnist', verbose=False)\n",
    "x_train_split, y_train_split, x_val_split, y_val_split = train_val_split(x_train, y_train)\n",
    "\n",
    "# KEEP ME\n",
    "print(f'Your training set data have shape {x_train_split.shape} and they should be (54000, 784)')\n",
    "print(f'Your training set labels have shape {y_train_split.shape} and they should be (54000,)')\n",
    "print(f'Your val set data have shape {x_val_split.shape} and they should be (6000, 784)')\n",
    "print(f'Your val set labels have shape {y_val_split.shape} and they should be (6000,)')\n",
    "print(f'Your test set data have shape {x_test.shape} and they should be (10000, 784)')\n",
    "print(f'Your test set labels have shape {y_test.shape} and they should be (10000,)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d006ed5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------\n",
      "Dense layer output((784,)) shape: [1, 10]\n",
      "---------------------------------------------------------------------------\n",
      "Epoch 0/9, Training loss 0.531, Val loss 0.285, Val acc 0.9210\n",
      "Epoch 0 took: 0.9 secs\n",
      "Epoch 1/9, Training loss 0.325, Val loss 0.255, Val acc 0.9309\n",
      "Epoch 1 took: 0.8 secs\n",
      "Epoch 2/9, Training loss 0.293, Val loss 0.243, Val acc 0.9318\n",
      "Epoch 2 took: 0.7 secs\n",
      "Epoch 3/9, Training loss 0.279, Val loss 0.243, Val acc 0.9323\n",
      "Epoch 3 took: 0.7 secs\n",
      "Epoch 4/9, Training loss 0.276, Val loss 0.235, Val acc 0.9343\n",
      "Epoch 4 took: 0.7 secs\n",
      "Epoch 5/9, Training loss 0.269, Val loss 0.238, Val acc 0.9345\n",
      "Epoch 5 took: 0.7 secs\n",
      "Epoch 6/9, Training loss 0.271, Val loss 0.237, Val acc 0.9335\n",
      "Epoch 6 took: 0.7 secs\n",
      "Epoch 7/9, Training loss 0.267, Val loss 0.234, Val acc 0.9363\n",
      "Epoch 7 took: 0.7 secs\n",
      "Epoch 8/9, Training loss 0.261, Val loss 0.230, Val acc 0.9363\n",
      "Epoch 8 took: 0.7 secs\n",
      "Epoch 9/9, Training loss 0.265, Val loss 0.232, Val acc 0.9355\n",
      "Epoch 9 took: 0.7 secs\n",
      "Finished training after 10 epochs!\n",
      "Training took: 7.79 secs\n",
      "Test accuracy: 0.9227\n"
     ]
    }
   ],
   "source": [
    "# KEEP THIS SEED\n",
    "tf.random.set_seed(0)\n",
    "\n",
    "# Create the model\n",
    "model = LinearDecoder(input_feats_shape=(784,), C=10)\n",
    "# Compile the model\n",
    "model.compile()\n",
    "# Train the model\n",
    "train_loss_hist, val_loss_hist, val_acc_hist, e = model.fit(x_train_split, y_train_split, x_val=x_val_split, y_val=y_val_split, \n",
    "                                                            batch_size=256, max_epochs=10)\n",
    "# Evaluate the model on the test set\n",
    "test_acc, test_loss = model.evaluate(x_test, y_test)\n",
    "print(f'Test accuracy: {test_acc:.4f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
